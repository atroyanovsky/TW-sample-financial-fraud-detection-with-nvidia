{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IEEE-CIS Fraud Detection - Exploratory Data Analysis\n",
    "\n",
    "This notebook provides comprehensive EDA for the IEEE-CIS Fraud Detection dataset including:\n",
    "- Data overview and summary statistics\n",
    "- Missing value analysis\n",
    "- Distribution analysis (numerical and categorical)\n",
    "- Fraud class balance analysis\n",
    "- Correlation analysis\n",
    "- Temporal patterns\n",
    "- Interactive visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "# Interactive visualizations\n",
    "try:\n",
    "    import plotly.express as px\n",
    "    import plotly.graph_objects as go\n",
    "    from plotly.subplots import make_subplots\n",
    "    PLOTLY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    PLOTLY_AVAILABLE = False\n",
    "    print(\"Warning: plotly not installed. Run: pip install plotly\")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to IEEE_CIS data directory\n",
    "DATA_PATH = \"../data/IEEE_CIS\"\n",
    "\n",
    "# Sample fraction (set to None to use all data, or 0.1 for 10%)\n",
    "SAMPLE_FRACTION = 0.1  # Use 10% for faster exploration\n",
    "\n",
    "# Output directory for saved figures\n",
    "OUTPUT_DIR = \"eda_output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load transaction data\n",
    "transaction_path = os.path.join(DATA_PATH, \"raw\", \"train_transaction.csv\")\n",
    "print(f\"Loading transactions from: {transaction_path}\")\n",
    "\n",
    "# Define dtypes for efficient loading\n",
    "dtype_dict = {f'V{i}': 'float32' for i in range(1, 340)}\n",
    "dtype_dict.update({f'C{i}': 'float32' for i in range(1, 15)})\n",
    "dtype_dict.update({f'D{i}': 'float32' for i in range(1, 16)})\n",
    "dtype_dict.update({f'M{i}': 'object' for i in range(1, 10)})\n",
    "dtype_dict['TransactionAmt'] = 'float32'\n",
    "dtype_dict['TransactionDT'] = 'int64'\n",
    "dtype_dict['isFraud'] = 'int8'\n",
    "\n",
    "transactions = pd.read_csv(transaction_path, dtype=dtype_dict)\n",
    "print(f\"Loaded {len(transactions):,} transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load identity data\n",
    "identity_path = os.path.join(DATA_PATH, \"raw\", \"train_identity.csv\")\n",
    "print(f\"Loading identity from: {identity_path}\")\n",
    "\n",
    "identity = pd.read_csv(identity_path)\n",
    "print(f\"Loaded {len(identity):,} identity records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets\n",
    "print(\"Merging datasets...\")\n",
    "data = transactions.merge(identity, on='TransactionID', how='left')\n",
    "print(f\"Merged data: {len(data):,} rows, {len(data.columns)} columns\")\n",
    "\n",
    "del transactions, identity  # Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Sample data for faster exploration\n",
    "if SAMPLE_FRACTION is not None and SAMPLE_FRACTION < 1.0:\n",
    "    print(f\"Sampling {SAMPLE_FRACTION*100:.1f}% of data...\")\n",
    "    data = data.sample(frac=SAMPLE_FRACTION, random_state=42).reset_index(drop=True)\n",
    "    print(f\"Sampled data: {len(data):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add datetime column\n",
    "reference_date = datetime(2017, 11, 30)\n",
    "data['datetime'] = pd.to_datetime(\n",
    "    data['TransactionDT'].apply(lambda x: reference_date + timedelta(seconds=int(x)))\n",
    ")\n",
    "print(f\"Date range: {data['datetime'].min()} to {data['datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA OVERVIEW\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nShape: {data.shape[0]:,} rows √ó {data.shape[1]} columns\")\n",
    "print(f\"Memory usage: {data.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\nColumn Types:\")\n",
    "type_counts = data.dtypes.value_counts()\n",
    "for dtype, count in type_counts.items():\n",
    "    print(f\"  {dtype}: {count} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorize columns\n",
    "v_cols = [c for c in data.columns if c.startswith('V')]\n",
    "c_cols = [c for c in data.columns if c.startswith('C') and c[1:].isdigit()]\n",
    "d_cols = [c for c in data.columns if c.startswith('D') and c[1:].isdigit()]\n",
    "m_cols = [c for c in data.columns if c.startswith('M') and c[1:].isdigit()]\n",
    "id_cols = [c for c in data.columns if c.startswith('id_')]\n",
    "\n",
    "print(\"Column Groups:\")\n",
    "print(f\"  V features (Vesta): {len(v_cols)} columns\")\n",
    "print(f\"  C features (counting): {len(c_cols)} columns\")\n",
    "print(f\"  D features (timedelta): {len(d_cols)} columns\")\n",
    "print(f\"  M features (match): {len(m_cols)} columns\")\n",
    "print(f\"  Identity features: {len(id_cols)} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for key numerical columns\n",
    "key_num_cols = ['TransactionAmt', 'TransactionDT', 'card1', 'card2', 'card3', 'card5', \n",
    "                'addr1', 'addr2', 'dist1', 'dist2', 'isFraud']\n",
    "key_num_cols = [c for c in key_num_cols if c in data.columns]\n",
    "data[key_num_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Missing Value Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate missing values\n",
    "missing = pd.DataFrame({\n",
    "    'column': data.columns,\n",
    "    'missing_count': data.isnull().sum().values,\n",
    "    'missing_pct': (data.isnull().sum().values / len(data) * 100)\n",
    "})\n",
    "missing = missing.sort_values('missing_pct', ascending=False)\n",
    "missing_only = missing[missing['missing_count'] > 0]\n",
    "\n",
    "print(f\"Columns with missing values: {len(missing_only)} / {len(data.columns)}\")\n",
    "print(f\"Total missing cells: {data.isnull().sum().sum():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 20 columns by missing percentage\n",
    "missing_only.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize missing values\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart of top 30 missing columns\n",
    "top_missing = missing_only.head(30)\n",
    "ax1 = axes[0]\n",
    "ax1.barh(range(len(top_missing)), top_missing['missing_pct'].values, color='coral')\n",
    "ax1.set_yticks(range(len(top_missing)))\n",
    "ax1.set_yticklabels(top_missing['column'].values, fontsize=8)\n",
    "ax1.set_xlabel('Missing %')\n",
    "ax1.set_title('Top 30 Columns by Missing Values', fontsize=12, fontweight='bold')\n",
    "ax1.invert_yaxis()\n",
    "\n",
    "# Missing value distribution histogram\n",
    "ax2 = axes[1]\n",
    "ax2.hist(missing_only['missing_pct'], bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax2.set_xlabel('Missing %')\n",
    "ax2.set_ylabel('Number of Columns')\n",
    "ax2.set_title('Distribution of Missing Value Percentages', fontsize=12, fontweight='bold')\n",
    "ax2.axvline(missing_only['missing_pct'].median(), color='red', linestyle='--', \n",
    "            label=f'Median: {missing_only[\"missing_pct\"].median():.1f}%')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'missing_values.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Fraud Target Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_counts = data['isFraud'].value_counts()\n",
    "fraud_pct = data['isFraud'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"Fraud Distribution:\")\n",
    "print(f\"  Non-Fraud (0): {fraud_counts[0]:,} ({fraud_pct[0]:.2f}%)\")\n",
    "print(f\"  Fraud (1):     {fraud_counts[1]:,} ({fraud_pct[1]:.2f}%)\")\n",
    "print(f\"  Imbalance Ratio: {fraud_counts[0] / fraud_counts[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize fraud distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "\n",
    "# Pie chart\n",
    "ax1 = axes[0]\n",
    "ax1.pie([fraud_counts[0], fraud_counts[1]], \n",
    "        explode=(0, 0.1), labels=['Non-Fraud', 'Fraud'],\n",
    "        colors=colors, autopct='%1.2f%%', startangle=90)\n",
    "ax1.set_title('Fraud Distribution', fontsize=12, fontweight='bold')\n",
    "\n",
    "# Bar chart\n",
    "ax2 = axes[1]\n",
    "bars = ax2.bar(['Non-Fraud', 'Fraud'], [fraud_counts[0], fraud_counts[1]], \n",
    "               color=colors, edgecolor='black')\n",
    "ax2.set_ylabel('Count')\n",
    "ax2.set_title('Transaction Counts', fontsize=12, fontweight='bold')\n",
    "for bar, val in zip(bars, [fraud_counts[0], fraud_counts[1]]):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1000, \n",
    "            f'{val:,}', ha='center', fontsize=10)\n",
    "\n",
    "# Log scale bar chart\n",
    "ax3 = axes[2]\n",
    "ax3.bar(['Non-Fraud', 'Fraud'], [fraud_counts[0], fraud_counts[1]], \n",
    "        color=colors, edgecolor='black')\n",
    "ax3.set_ylabel('Count (log scale)')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_title('Transaction Counts (Log Scale)', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'fraud_distribution.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Transaction Amount Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amount = data['TransactionAmt']\n",
    "fraud = data['isFraud']\n",
    "\n",
    "print(\"Overall Statistics:\")\n",
    "print(f\"  Mean:   ${amount.mean():.2f}\")\n",
    "print(f\"  Median: ${amount.median():.2f}\")\n",
    "print(f\"  Std:    ${amount.std():.2f}\")\n",
    "print(f\"  Min:    ${amount.min():.2f}\")\n",
    "print(f\"  Max:    ${amount.max():.2f}\")\n",
    "\n",
    "print(f\"\\nBy Fraud Status:\")\n",
    "for label, name in [(0, 'Non-Fraud'), (1, 'Fraud')]:\n",
    "    subset = amount[fraud == label]\n",
    "    print(f\"  {name}: Mean=${subset.mean():.2f}, Median=${subset.median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize transaction amounts\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Distribution (clipped)\n",
    "ax = axes[0, 0]\n",
    "ax.hist(amount.clip(upper=amount.quantile(0.99)), bins=100, \n",
    "        color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Transaction Amount ($)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Amount Distribution (99th percentile)', fontweight='bold')\n",
    "\n",
    "# Log distribution\n",
    "ax = axes[0, 1]\n",
    "ax.hist(np.log1p(amount), bins=100, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Log(Amount + 1)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Log-Transformed Distribution', fontweight='bold')\n",
    "\n",
    "# Box plot by fraud\n",
    "ax = axes[0, 2]\n",
    "fraud_amounts = [amount[fraud == 0], amount[fraud == 1]]\n",
    "bp = ax.boxplot(fraud_amounts, labels=['Non-Fraud', 'Fraud'], patch_artist=True)\n",
    "bp['boxes'][0].set_facecolor('#2ecc71')\n",
    "bp['boxes'][1].set_facecolor('#e74c3c')\n",
    "ax.set_ylabel('Transaction Amount ($)')\n",
    "ax.set_title('Amount by Fraud Status', fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Density by fraud status\n",
    "ax = axes[1, 0]\n",
    "for label, name, color in [(0, 'Non-Fraud', '#2ecc71'), (1, 'Fraud', '#e74c3c')]:\n",
    "    subset = np.log1p(amount[fraud == label])\n",
    "    sns.kdeplot(subset, ax=ax, label=name, color=color, fill=True, alpha=0.3)\n",
    "ax.set_xlabel('Log(Amount + 1)')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Amount Density by Fraud Status', fontweight='bold')\n",
    "ax.legend()\n",
    "\n",
    "# Amount percentiles\n",
    "ax = axes[1, 1]\n",
    "percentiles = [1, 5, 10, 25, 50, 75, 90, 95, 99]\n",
    "pct_values = [amount.quantile(p/100) for p in percentiles]\n",
    "ax.bar(range(len(percentiles)), pct_values, color='teal', edgecolor='black')\n",
    "ax.set_xticks(range(len(percentiles)))\n",
    "ax.set_xticklabels([f'{p}%' for p in percentiles])\n",
    "ax.set_ylabel('Amount ($)')\n",
    "ax.set_title('Amount Percentiles', fontweight='bold')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "# Fraud rate by amount bin\n",
    "ax = axes[1, 2]\n",
    "data_temp = data[['TransactionAmt', 'isFraud']].copy()\n",
    "data_temp['amount_bin'] = pd.qcut(data_temp['TransactionAmt'], q=10, duplicates='drop')\n",
    "fraud_rate_by_bin = data_temp.groupby('amount_bin')['isFraud'].mean() * 100\n",
    "fraud_rate_by_bin.plot(kind='bar', ax=ax, color='purple', edgecolor='black')\n",
    "ax.set_xlabel('Amount Bin')\n",
    "ax.set_ylabel('Fraud Rate (%)')\n",
    "ax.set_title('Fraud Rate by Amount Bin', fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'transaction_amount.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Categorical Feature Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', \n",
    "            'DeviceType', 'DeviceInfo']\n",
    "cat_cols = [c for c in cat_cols if c in data.columns]\n",
    "\n",
    "for col in cat_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Unique values: {data[col].nunique()}\")\n",
    "    print(f\"  Missing: {data[col].isnull().sum()} ({data[col].isnull().mean()*100:.1f}%)\")\n",
    "    print(f\"  Top 3: {data[col].value_counts().head(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fraud rate by categorical features\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, col in enumerate(cat_cols[:6]):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Calculate fraud rate by category\n",
    "    fraud_rate = data.groupby(col)['isFraud'].agg(['mean', 'count'])\n",
    "    fraud_rate = fraud_rate.sort_values('count', ascending=False).head(10)\n",
    "    \n",
    "    # Plot\n",
    "    x = range(len(fraud_rate))\n",
    "    bars = ax.bar(x, fraud_rate['mean'] * 100, color='steelblue', edgecolor='black', alpha=0.8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(fraud_rate.index, rotation=45, ha='right', fontsize=8)\n",
    "    ax.set_ylabel('Fraud Rate (%)')\n",
    "    ax.set_title(f'Fraud Rate by {col}', fontweight='bold')\n",
    "\n",
    "for idx in range(len(cat_cols), len(axes)):\n",
    "    axes[idx].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'categorical_features.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ProductCD and Card detailed analysis\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# ProductCD distribution\n",
    "ax = axes[0, 0]\n",
    "product_counts = data['ProductCD'].value_counts()\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(product_counts)))\n",
    "ax.pie(product_counts, labels=product_counts.index, colors=colors, autopct='%1.1f%%')\n",
    "ax.set_title('ProductCD Distribution', fontweight='bold')\n",
    "\n",
    "# ProductCD fraud rate\n",
    "ax = axes[0, 1]\n",
    "product_fraud = data.groupby('ProductCD')['isFraud'].mean() * 100\n",
    "bars = ax.bar(product_fraud.index, product_fraud.values, color='coral', edgecolor='black')\n",
    "ax.set_ylabel('Fraud Rate (%)')\n",
    "ax.set_title('Fraud Rate by ProductCD', fontweight='bold')\n",
    "for bar, val in zip(bars, product_fraud.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.3, \n",
    "           f'{val:.1f}%', ha='center', fontsize=9)\n",
    "\n",
    "# Card4 (card brand)\n",
    "ax = axes[0, 2]\n",
    "if 'card4' in data.columns:\n",
    "    card4_fraud = data.groupby('card4')['isFraud'].mean() * 100\n",
    "    card4_fraud = card4_fraud.sort_values(ascending=False)\n",
    "    ax.barh(range(len(card4_fraud)), card4_fraud.values, color='teal', edgecolor='black')\n",
    "    ax.set_yticks(range(len(card4_fraud)))\n",
    "    ax.set_yticklabels(card4_fraud.index)\n",
    "    ax.set_xlabel('Fraud Rate (%)')\n",
    "    ax.set_title('Fraud Rate by Card Brand (card4)', fontweight='bold')\n",
    "\n",
    "# Card6 (card type)\n",
    "ax = axes[1, 0]\n",
    "if 'card6' in data.columns:\n",
    "    card6_counts = data['card6'].value_counts()\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71', '#f1c40f'][:len(card6_counts)]\n",
    "    ax.pie(card6_counts, labels=card6_counts.index, colors=colors, autopct='%1.1f%%')\n",
    "    ax.set_title('Card Type (card6) Distribution', fontweight='bold')\n",
    "\n",
    "# Card6 fraud rate\n",
    "ax = axes[1, 1]\n",
    "if 'card6' in data.columns:\n",
    "    card6_fraud = data.groupby('card6')['isFraud'].mean() * 100\n",
    "    bars = ax.bar(card6_fraud.index, card6_fraud.values, color='purple', edgecolor='black')\n",
    "    ax.set_ylabel('Fraud Rate (%)')\n",
    "    ax.set_title('Fraud Rate by Card Type', fontweight='bold')\n",
    "\n",
    "# Cross-tabulation heatmap\n",
    "ax = axes[1, 2]\n",
    "if 'card6' in data.columns:\n",
    "    cross_fraud = data.pivot_table(values='isFraud', index='ProductCD', \n",
    "                                    columns='card6', aggfunc='mean') * 100\n",
    "    sns.heatmap(cross_fraud, annot=True, fmt='.1f', cmap='Reds', ax=ax, \n",
    "               cbar_kws={'label': 'Fraud Rate (%)'})\n",
    "    ax.set_title('Fraud Rate: ProductCD √ó Card Type', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'product_card_analysis.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. V Features Analysis (Vesta Engineered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_cols = [c for c in data.columns if c.startswith('V')]\n",
    "print(f\"Number of V features: {len(v_cols)}\")\n",
    "\n",
    "# Missing value analysis\n",
    "v_missing = data[v_cols].isnull().sum() / len(data) * 100\n",
    "print(f\"\\nV Features Missing Value Summary:\")\n",
    "print(f\"  Mean missing %: {v_missing.mean():.1f}%\")\n",
    "print(f\"  Max missing %:  {v_missing.max():.1f}%\")\n",
    "print(f\"  Features with >50% missing: {(v_missing > 50).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with fraud\n",
    "v_fraud_corr = {}\n",
    "for col in v_cols:\n",
    "    if data[col].notna().sum() > 100:\n",
    "        corr = data[col].corr(data['isFraud'])\n",
    "        if not np.isnan(corr):\n",
    "            v_fraud_corr[col] = corr\n",
    "\n",
    "sorted_corr = sorted(v_fraud_corr.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top 15 V features by absolute correlation with fraud:\")\n",
    "for col, corr in sorted_corr[:15]:\n",
    "    print(f\"  {col}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize V features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Missing values\n",
    "ax = axes[0, 0]\n",
    "ax.hist(v_missing, bins=50, color='coral', edgecolor='black', alpha=0.7)\n",
    "ax.set_xlabel('Missing %')\n",
    "ax.set_ylabel('Number of V Features')\n",
    "ax.set_title('Missing Value Distribution in V Features', fontweight='bold')\n",
    "\n",
    "# Correlation distribution\n",
    "ax = axes[0, 1]\n",
    "corr_values = list(v_fraud_corr.values())\n",
    "ax.hist(corr_values, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Correlation with Fraud')\n",
    "ax.set_ylabel('Number of V Features')\n",
    "ax.set_title('V Features Correlation with Fraud', fontweight='bold')\n",
    "\n",
    "# Top correlations\n",
    "ax = axes[1, 0]\n",
    "top_pos = sorted_corr[:15]\n",
    "cols = [x[0] for x in top_pos]\n",
    "vals = [x[1] for x in top_pos]\n",
    "colors = ['#e74c3c' if v > 0 else '#3498db' for v in vals]\n",
    "ax.barh(range(len(cols)), vals, color=colors)\n",
    "ax.set_yticks(range(len(cols)))\n",
    "ax.set_yticklabels(cols)\n",
    "ax.set_xlabel('Correlation with Fraud')\n",
    "ax.set_title('Top 15 V Features by Correlation', fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Top V feature distribution by fraud\n",
    "ax = axes[1, 1]\n",
    "if len(sorted_corr) > 0:\n",
    "    top_v = sorted_corr[0][0]\n",
    "    for label, name, color in [(0, 'Non-Fraud', '#2ecc71'), (1, 'Fraud', '#e74c3c')]:\n",
    "        subset = data[data['isFraud'] == label][top_v].dropna()\n",
    "        if len(subset) > 0:\n",
    "            sns.kdeplot(subset.clip(subset.quantile(0.01), subset.quantile(0.99)), \n",
    "                       ax=ax, label=name, color=color, fill=True, alpha=0.3)\n",
    "    ax.set_xlabel(top_v)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.set_title(f'{top_v} Distribution by Fraud Status', fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'v_features.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 8. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract time features\n",
    "data['hour'] = data['datetime'].dt.hour\n",
    "data['day_of_week'] = data['datetime'].dt.dayofweek\n",
    "data['day_of_month'] = data['datetime'].dt.day\n",
    "data['date'] = data['datetime'].dt.date\n",
    "\n",
    "print(\"Hourly Pattern:\")\n",
    "hourly_fraud = data.groupby('hour')['isFraud'].mean() * 100\n",
    "print(f\"  Peak fraud hour: {hourly_fraud.idxmax()} ({hourly_fraud.max():.2f}%)\")\n",
    "print(f\"  Lowest fraud hour: {hourly_fraud.idxmin()} ({hourly_fraud.min():.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal visualizations\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 10))\n",
    "\n",
    "# Daily transaction volume\n",
    "ax = axes[0, 0]\n",
    "daily_txn = data.groupby('date').size()\n",
    "ax.plot(daily_txn.index, daily_txn.values, color='steelblue', alpha=0.7)\n",
    "ax.fill_between(daily_txn.index, daily_txn.values, alpha=0.3)\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Transaction Count')\n",
    "ax.set_title('Daily Transaction Volume', fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Daily fraud rate\n",
    "ax = axes[0, 1]\n",
    "daily_fraud = data.groupby('date')['isFraud'].mean() * 100\n",
    "ax.plot(daily_fraud.index, daily_fraud.values, color='#e74c3c', alpha=0.7)\n",
    "ax.fill_between(daily_fraud.index, daily_fraud.values, alpha=0.3, color='#e74c3c')\n",
    "ax.set_xlabel('Date')\n",
    "ax.set_ylabel('Fraud Rate (%)')\n",
    "ax.set_title('Daily Fraud Rate', fontweight='bold')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Hourly pattern\n",
    "ax = axes[0, 2]\n",
    "hourly_stats = data.groupby('hour').agg({'isFraud': 'mean', 'TransactionAmt': 'count'})\n",
    "ax2 = ax.twinx()\n",
    "ax.bar(hourly_stats.index, hourly_stats['isFraud'] * 100, alpha=0.7, color='coral', label='Fraud Rate')\n",
    "ax2.plot(hourly_stats.index, hourly_stats['TransactionAmt'], color='steelblue', linewidth=2, marker='o')\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Fraud Rate (%)', color='coral')\n",
    "ax2.set_ylabel('Transaction Count', color='steelblue')\n",
    "ax.set_title('Hourly Patterns', fontweight='bold')\n",
    "ax.set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Day of week\n",
    "ax = axes[1, 0]\n",
    "dow_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "dow_fraud = data.groupby('day_of_week')['isFraud'].mean() * 100\n",
    "ax.bar(dow_names, dow_fraud.values, color='teal', edgecolor='black')\n",
    "ax.set_ylabel('Fraud Rate (%)')\n",
    "ax.set_title('Fraud Rate by Day of Week', fontweight='bold')\n",
    "\n",
    "# Amount by hour\n",
    "ax = axes[1, 1]\n",
    "hourly_amt = data.groupby('hour')['TransactionAmt'].agg(['mean', 'median'])\n",
    "ax.plot(hourly_amt.index, hourly_amt['mean'], marker='o', label='Mean', color='steelblue')\n",
    "ax.plot(hourly_amt.index, hourly_amt['median'], marker='s', label='Median', color='coral')\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Transaction Amount ($)')\n",
    "ax.set_title('Transaction Amount by Hour', fontweight='bold')\n",
    "ax.legend()\n",
    "ax.set_xticks(range(0, 24, 2))\n",
    "\n",
    "# Fraud heatmap: hour vs day\n",
    "ax = axes[1, 2]\n",
    "heatmap_data = data.pivot_table(values='isFraud', index='day_of_week', \n",
    "                                 columns='hour', aggfunc='mean') * 100\n",
    "heatmap_data.index = dow_names\n",
    "sns.heatmap(heatmap_data, cmap='Reds', ax=ax, cbar_kws={'label': 'Fraud Rate (%)'})\n",
    "ax.set_xlabel('Hour of Day')\n",
    "ax.set_ylabel('Day of Week')\n",
    "ax.set_title('Fraud Rate: Day √ó Hour', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'temporal_patterns.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlations with fraud for all numerical columns\n",
    "num_cols = data.select_dtypes(include=[np.number]).columns.tolist()\n",
    "num_cols = [c for c in num_cols if c not in ['isFraud', 'TransactionID']]\n",
    "\n",
    "fraud_corr = {}\n",
    "for col in num_cols:\n",
    "    if data[col].notna().sum() > 100:\n",
    "        corr = data[col].corr(data['isFraud'])\n",
    "        if not np.isnan(corr):\n",
    "            fraud_corr[col] = corr\n",
    "\n",
    "sorted_all_corr = sorted(fraud_corr.items(), key=lambda x: abs(x[1]), reverse=True)\n",
    "\n",
    "print(\"Top 20 features by absolute correlation with fraud:\")\n",
    "for col, corr in sorted_all_corr[:20]:\n",
    "    print(f\"  {col:30s}: {corr:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlations\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 8))\n",
    "\n",
    "# Top correlations\n",
    "ax = axes[0]\n",
    "top_30 = sorted_all_corr[:30]\n",
    "cols = [x[0] for x in top_30]\n",
    "vals = [x[1] for x in top_30]\n",
    "colors = ['#e74c3c' if c > 0 else '#3498db' for c in vals]\n",
    "ax.barh(range(len(cols)), vals, color=colors)\n",
    "ax.set_yticks(range(len(cols)))\n",
    "ax.set_yticklabels(cols, fontsize=8)\n",
    "ax.set_xlabel('Correlation with Fraud')\n",
    "ax.set_title('Top 30 Features by Correlation', fontweight='bold')\n",
    "ax.axvline(0, color='black', linewidth=0.5)\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Correlation distribution\n",
    "ax = axes[1]\n",
    "all_corrs = [x[1] for x in sorted_all_corr]\n",
    "ax.hist(all_corrs, bins=50, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax.axvline(0, color='red', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Correlation with Fraud')\n",
    "ax.set_ylabel('Number of Features')\n",
    "ax.set_title('Distribution of Feature Correlations', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'correlations.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for key features\n",
    "key_features = ['TransactionAmt', 'card1', 'card2', 'card3', 'card5',\n",
    "               'addr1', 'addr2', 'dist1', 'dist2', 'isFraud']\n",
    "key_features = [f for f in key_features if f in data.columns]\n",
    "\n",
    "corr_matrix = data[key_features].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap='RdBu_r',\n",
    "            center=0, square=True, linewidths=0.5)\n",
    "plt.title('Feature Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, 'correlation_matrix.png'), dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 10. Interactive Visualizations (Plotly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PLOTLY_AVAILABLE:\n",
    "    # Sample for performance\n",
    "    sample_size = min(50000, len(data))\n",
    "    sample_data = data.sample(sample_size, random_state=42)\n",
    "    print(f\"Using {sample_size:,} samples for interactive plots\")\n",
    "else:\n",
    "    print(\"Plotly not available. Install with: pip install plotly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive box plot: Amount by Fraud Status\n",
    "if PLOTLY_AVAILABLE:\n",
    "    fig = px.box(sample_data, x='isFraud', y='TransactionAmt', \n",
    "                  color='isFraud', log_y=True,\n",
    "                  title='Transaction Amount by Fraud Status',\n",
    "                  labels={'isFraud': 'Is Fraud', 'TransactionAmt': 'Amount ($)'},\n",
    "                  color_discrete_map={0: '#2ecc71', 1: '#e74c3c'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive sunburst: ProductCD ‚Üí card4 ‚Üí Fraud\n",
    "if PLOTLY_AVAILABLE and 'card4' in sample_data.columns:\n",
    "    sunburst_data = sample_data.groupby(['ProductCD', 'card4', 'isFraud']).size().reset_index(name='count')\n",
    "    fig = px.sunburst(sunburst_data, path=['ProductCD', 'card4', 'isFraud'], \n",
    "                       values='count', title='Transaction Hierarchy: Product ‚Üí Card Brand ‚Üí Fraud')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive time series\n",
    "if PLOTLY_AVAILABLE:\n",
    "    daily_stats = sample_data.groupby('date').agg({\n",
    "        'isFraud': ['sum', 'mean', 'count']\n",
    "    }).reset_index()\n",
    "    daily_stats.columns = ['date', 'fraud_count', 'fraud_rate', 'total_count']\n",
    "    daily_stats['fraud_rate'] *= 100\n",
    "    \n",
    "    fig = make_subplots(rows=2, cols=1, shared_xaxes=True,\n",
    "                         subplot_titles=('Daily Transaction Volume', 'Daily Fraud Rate (%)'))\n",
    "    fig.add_trace(go.Scatter(x=daily_stats['date'], y=daily_stats['total_count'],\n",
    "                              fill='tozeroy', name='Transactions'), row=1, col=1)\n",
    "    fig.add_trace(go.Scatter(x=daily_stats['date'], y=daily_stats['fraud_rate'],\n",
    "                              fill='tozeroy', name='Fraud Rate', line=dict(color='red')), row=2, col=1)\n",
    "    fig.update_layout(title='Time Series Analysis', height=600)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive 3D scatter\n",
    "if PLOTLY_AVAILABLE:\n",
    "    scatter_sample = sample_data.sample(min(10000, len(sample_data)))\n",
    "    fig = px.scatter_3d(scatter_sample, \n",
    "                         x='TransactionAmt', y='hour', z='card1',\n",
    "                         color='isFraud', opacity=0.5,\n",
    "                         title='3D View: Amount √ó Hour √ó Card1',\n",
    "                         color_discrete_map={0: '#2ecc71', 1: '#e74c3c'})\n",
    "    fig.update_traces(marker=dict(size=3))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallel coordinates\n",
    "if PLOTLY_AVAILABLE:\n",
    "    parallel_features = ['TransactionAmt', 'card1', 'addr1', 'dist1', 'isFraud']\n",
    "    parallel_features = [f for f in parallel_features if f in sample_data.columns]\n",
    "    parallel_sample = sample_data[parallel_features].dropna().sample(min(5000, len(sample_data)))\n",
    "    \n",
    "    fig = px.parallel_coordinates(parallel_sample, color='isFraud',\n",
    "                                   title='Parallel Coordinates: Key Features',\n",
    "                                   color_continuous_scale=[[0, '#2ecc71'], [1, '#e74c3c']])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 11. Summary & Key Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"  IEEE-CIS FRAUD DETECTION - EDA SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüìä Dataset Size: {len(data):,} transactions, {len(data.columns)} features\")\n",
    "print(f\"üìÖ Date Range: {data['datetime'].min().date()} to {data['datetime'].max().date()}\")\n",
    "\n",
    "fraud_rate = data['isFraud'].mean() * 100\n",
    "print(f\"\\nüéØ Fraud Rate: {fraud_rate:.2f}%\")\n",
    "print(f\"   Imbalance Ratio: {(100-fraud_rate)/fraud_rate:.1f}:1\")\n",
    "\n",
    "print(f\"\\nüí∞ Transaction Amount:\")\n",
    "print(f\"   Mean: ${data['TransactionAmt'].mean():.2f}\")\n",
    "print(f\"   Median: ${data['TransactionAmt'].median():.2f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Missing Values:\")\n",
    "cols_with_missing = (data.isnull().sum() > 0).sum()\n",
    "print(f\"   {cols_with_missing} columns with missing values\")\n",
    "print(f\"   {(data.isnull().sum() > len(data)*0.5).sum()} columns with >50% missing\")\n",
    "\n",
    "print(f\"\\nüîó Top 5 Correlated Features:\")\n",
    "for col, corr in sorted_all_corr[:5]:\n",
    "    print(f\"   {col}: {corr:+.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Outputs saved to: {OUTPUT_DIR}/\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save correlation data\n",
    "corr_df = pd.DataFrame(sorted_all_corr, columns=['feature', 'correlation'])\n",
    "corr_df.to_csv(os.path.join(OUTPUT_DIR, 'feature_correlations.csv'), index=False)\n",
    "print(f\"Saved feature correlations to {OUTPUT_DIR}/feature_correlations.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
